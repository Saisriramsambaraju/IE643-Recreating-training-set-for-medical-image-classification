{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a7592e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:10.891907Z",
     "iopub.status.busy": "2024-11-01T17:21:10.891125Z",
     "iopub.status.idle": "2024-11-01T17:21:18.958977Z",
     "shell.execute_reply": "2024-11-01T17:21:18.958187Z"
    },
    "papermill": {
     "duration": 8.077333,
     "end_time": "2024-11-01T17:21:18.961289",
     "exception": false,
     "start_time": "2024-11-01T17:21:10.883956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98698bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:18.973409Z",
     "iopub.status.busy": "2024-11-01T17:21:18.972968Z",
     "iopub.status.idle": "2024-11-01T17:21:19.097207Z",
     "shell.execute_reply": "2024-11-01T17:21:19.096194Z"
    },
    "papermill": {
     "duration": 0.132495,
     "end_time": "2024-11-01T17:21:19.099359",
     "exception": false,
     "start_time": "2024-11-01T17:21:18.966864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)  # Set the current device to the first GPU\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class VGG16_MRI(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VGG16_MRI, self).__init__()\n",
    "        # Load a pre-trained VGG16 model with batch normalization\n",
    "        model = torchvision.models.vgg16_bn(pretrained=True)\n",
    "        \n",
    "        # Change the first convolutional layer to accept single-channel (grayscale) input\n",
    "        model.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        \n",
    "        # Retain the feature extraction layers\n",
    "        self.feature = model.features\n",
    "        \n",
    "        # Define the feature dimension based on output size for 240x240 input\n",
    "        # VGG16 feature output will be (512, 7, 7) for 224x224, so we calculate for 240x240\n",
    "        self.feat_dim = 512 * 7 * 7  # Update this if output size changes with input size\n",
    "        \n",
    "        # Adjust the number of classes for binary classification (0 or 1)\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Batch normalization layer\n",
    "        self.bn = nn.BatchNorm1d(self.feat_dim)\n",
    "        self.bn.bias.requires_grad_(False)  # no shift\n",
    "        \n",
    "        # Fully connected layer to map features to the number of classes\n",
    "        self.fc_layer = nn.Linear(self.feat_dim, self.num_classes)\n",
    "        \n",
    "        self.model = model\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # Pass input through feature extraction layers\n",
    "        feature = self.feature(x)\n",
    "        feature = feature.view(feature.size(0), -1)  # Flatten the feature map\n",
    "        feature = self.bn(feature)  # Apply batch normalization\n",
    "        res = self.fc_layer(feature)  # Output class scores\n",
    "        \n",
    "        return feature, res\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Pass input through feature extraction layers\n",
    "        feature = self.feature(x)\n",
    "        feature = feature.view(feature.size(0), -1)  # Flatten the feature map\n",
    "        feature = self.bn(feature)  # Apply batch normalization\n",
    "        res = self.fc_layer(feature)  # Output class scores\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498ddec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.111541Z",
     "iopub.status.busy": "2024-11-01T17:21:19.111238Z",
     "iopub.status.idle": "2024-11-01T17:21:19.118522Z",
     "shell.execute_reply": "2024-11-01T17:21:19.117745Z"
    },
    "papermill": {
     "duration": 0.015363,
     "end_time": "2024-11-01T17:21:19.120422",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.105059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, df, data_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_dir, self.df.iloc[idx]['filename'])\n",
    "        image = Image.open(img_name).convert('L')  # Convert to grayscale\n",
    "        label = int(self.df.iloc[idx]['label'])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define image transformations (normalization can be adjusted based on data needs)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((240, 240)),  # Ensure image size is 240x240\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fbf4f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.132068Z",
     "iopub.status.busy": "2024-11-01T17:21:19.131768Z",
     "iopub.status.idle": "2024-11-01T17:21:19.136443Z",
     "shell.execute_reply": "2024-11-01T17:21:19.135699Z"
    },
    "papermill": {
     "duration": 0.012512,
     "end_time": "2024-11-01T17:21:19.138241",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.125729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_pretrained_classifier(path=None):\n",
    "    if path is None:\n",
    "        path = \"/kaggle/input/brats23-classifier/pytorch/default/1/classifier.pt\"\n",
    "    model = VGG16_MRI(num_classes=2)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30bb9e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.150965Z",
     "iopub.status.busy": "2024-11-01T17:21:19.150655Z",
     "iopub.status.idle": "2024-11-01T17:21:19.155287Z",
     "shell.execute_reply": "2024-11-01T17:21:19.154412Z"
    },
    "papermill": {
     "duration": 0.012627,
     "end_time": "2024-11-01T17:21:19.157235",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.144608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_directory_if_not_exists(directory_path):\n",
    "    try:\n",
    "        os.makedirs(directory_path, exist_ok=True)\n",
    "        print(f\"Directory created successfully: {directory_path}\")\n",
    "    except OSError as error:\n",
    "        print(f\"Error creating directory: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab20558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.169150Z",
     "iopub.status.busy": "2024-11-01T17:21:19.168841Z",
     "iopub.status.idle": "2024-11-01T17:21:19.173378Z",
     "shell.execute_reply": "2024-11-01T17:21:19.172638Z"
    },
    "papermill": {
     "duration": 0.012597,
     "end_time": "2024-11-01T17:21:19.175257",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.162660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utils.py\n",
    "def freeze(net):\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad_(False) \n",
    "\n",
    "def unfreeze(net):\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c53efa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.187623Z",
     "iopub.status.busy": "2024-11-01T17:21:19.186944Z",
     "iopub.status.idle": "2024-11-01T17:21:19.195586Z",
     "shell.execute_reply": "2024-11-01T17:21:19.194801Z"
    },
    "papermill": {
     "duration": 0.016691,
     "end_time": "2024-11-01T17:21:19.197478",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.180787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_dim=100, dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        def dconv_bn_relu(in_dim, out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_dim, out_dim, 5, 2, padding=2, output_padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_dim),\n",
    "                nn.ReLU())\n",
    "        \n",
    "        # Fully connected layer to expand noise to a larger size\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(in_dim, dim * 8 * 15 * 15, bias=False),\n",
    "            nn.BatchNorm1d(dim * 8 * 15 * 15),\n",
    "            nn.ReLU())\n",
    "\n",
    "        # Deconvolutional layers for upsampling to 240x240\n",
    "        self.l2_5 = nn.Sequential(\n",
    "            dconv_bn_relu(dim * 8, dim * 4),   # 15x15 -> 30x30\n",
    "            dconv_bn_relu(dim * 4, dim * 2),   # 30x30 -> 60x60\n",
    "            dconv_bn_relu(dim * 2, dim),       # 60x60 -> 120x120\n",
    "            nn.ConvTranspose2d(dim, 1, 5, 2, padding=2, output_padding=1),  # 120x120 -> 240x240\n",
    "            nn.Sigmoid())  # Output pixel values in range [0, 1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.l1(x)\n",
    "        y = y.view(y.size(0), -1, 15, 15)\n",
    "        y = self.l2_5(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f055a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.210156Z",
     "iopub.status.busy": "2024-11-01T17:21:19.209804Z",
     "iopub.status.idle": "2024-11-01T17:21:19.226717Z",
     "shell.execute_reply": "2024-11-01T17:21:19.226026Z"
    },
    "papermill": {
     "duration": 0.02568,
     "end_time": "2024-11-01T17:21:19.228684",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.203004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Discriminator discri.py \n",
    "class MinibatchDiscrimination(nn.Module):\n",
    "    def __init__(self, in_features, out_features, kernel_dims, mean=False):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.kernel_dims = kernel_dims\n",
    "        self.mean = mean\n",
    "        self.T = nn.Parameter(torch.Tensor(in_features, out_features, kernel_dims))\n",
    "        init.normal(self.T, 0, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is NxA\n",
    "        # T is AxBxC\n",
    "        matrices = x.mm(self.T.view(self.in_features, -1))\n",
    "        matrices = matrices.view(-1, self.out_features, self.kernel_dims)\n",
    "\n",
    "        M = matrices.unsqueeze(0)  # 1xNxBxC\n",
    "        M_T = M.permute(1, 0, 2, 3)  # Nx1xBxC\n",
    "        norm = torch.abs(M - M_T).sum(3)  # NxNxB\n",
    "        expnorm = torch.exp(-norm)\n",
    "        o_b = (expnorm.sum(0) - 1)   # NxB, subtract self distance\n",
    "        if self.mean:\n",
    "            o_b /= x.size(0) - 1\n",
    "\n",
    "        x = torch.cat([x, o_b], 1)\n",
    "        return x\n",
    "\n",
    "class MinibatchDiscriminator(nn.Module):\n",
    "    def __init__(self,in_dim=1, dim=64, n_classes=1000):\n",
    "        super(MinibatchDiscriminator, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        def conv_ln_lrelu(in_dim, out_dim, k, s, p):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_dim, out_dim, k, s, p),\n",
    "                # Since there is no effective implementation of LayerNorm,\n",
    "                # we use InstanceNorm2d instead of LayerNorm here.\n",
    "                nn.InstanceNorm2d(out_dim, affine=True),\n",
    "                nn.LeakyReLU(0.2))\n",
    "\n",
    "        self.layer1 = conv_ln_lrelu(in_dim, dim, 5, 2, 2)\n",
    "        self.layer2 = conv_ln_lrelu(dim, dim*2, 5, 2, 2)\n",
    "        self.layer3 = conv_ln_lrelu(dim*2, dim*4, 5, 2, 2)\n",
    "        self.layer4 = conv_ln_lrelu(dim*4, dim*4, 3, 2, 1)\n",
    "        self.mbd1 = MinibatchDiscrimination(57600, 64, 50)\n",
    "        self.fc_layer = nn.Linear(57600+64, self.n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        bs = x.shape[0]\n",
    "        feat1 = self.layer1(x)\n",
    "        out.append(feat1)\n",
    "        feat2 = self.layer2(feat1)\n",
    "        out.append(feat2)\n",
    "        feat3 = self.layer3(feat2)\n",
    "        out.append(feat3)\n",
    "        feat4 = self.layer4(feat3)\n",
    "        out.append(feat4)\n",
    "        feat = feat4.view(bs, -1)\n",
    "        # print('feat:', feat.shape)\n",
    "        mb_out = self.mbd1(feat)   # Nx(A+B)\n",
    "        y = self.fc_layer(mb_out)\n",
    "        \n",
    "        return feat, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e7a40a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.241327Z",
     "iopub.status.busy": "2024-11-01T17:21:19.241058Z",
     "iopub.status.idle": "2024-11-01T17:21:19.248140Z",
     "shell.execute_reply": "2024-11-01T17:21:19.247329Z"
    },
    "papermill": {
     "duration": 0.015494,
     "end_time": "2024-11-01T17:21:19.249930",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.234436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_GAN(n_classes, z_dim, Pretrained = False):\n",
    "\n",
    "    # if Pretrained :\n",
    "        # G= \n",
    "    # else :\n",
    "    G = Generator(z_dim)\n",
    "    D = MinibatchDiscriminator(n_classes=n_classes)\n",
    "    \n",
    "    G = torch.nn.DataParallel(G).to(device)\n",
    "    D = torch.nn.DataParallel(D).to(device)\n",
    "    if Pretrained:\n",
    "#         root_path = \"/kaggle/working/attack_results\"\n",
    "        dataset_name = \"BraTS23\"\n",
    "#         mode_name_T = \"VGG16_MRI\"\n",
    "#         path = os.path.join(root_path, os.path.join(dataset_name, model_name_T))\n",
    "#         path = \"/kaggle/input/brats23-gan-epoch25/pytorch/default/1\"\n",
    "        path = \"/kaggle/input/brats23-gan-epoch75/pytorch/default/1/attack_results/BraTS23/VGG16_MRI\"\n",
    "        # path = os.path.join(os.path.join(gan_model_dir, dataset), target_model)\n",
    "        path_G = os.path.join(path, \"ep75_improved_{}_G.pt\".format(dataset_name))\n",
    "        path_D = os.path.join(path, \"ep75_improved_{}_D.pt\".format(dataset_name))\n",
    "        ckp_G = torch.load(path_G)\n",
    "        G.load_state_dict(ckp_G['state_dict'], strict=True)\n",
    "        ckp_D = torch.load(path_D)\n",
    "        D.load_state_dict(ckp_D['state_dict'], strict=True)\n",
    "        print(\"Loaded Pretrained Model (Specific GAN)\")\n",
    "    \n",
    "    return G, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa31cfb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.262642Z",
     "iopub.status.busy": "2024-11-01T17:21:19.261874Z",
     "iopub.status.idle": "2024-11-01T17:21:19.266298Z",
     "shell.execute_reply": "2024-11-01T17:21:19.265425Z"
    },
    "papermill": {
     "duration": 0.012709,
     "end_time": "2024-11-01T17:21:19.268267",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.255558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_augmodel():\n",
    "    # model = pretrained_VGG_MRI_model\n",
    "    model = load_pretrained_classifier()\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d1dcfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.280693Z",
     "iopub.status.busy": "2024-11-01T17:21:19.280412Z",
     "iopub.status.idle": "2024-11-01T17:21:19.288751Z",
     "shell.execute_reply": "2024-11-01T17:21:19.287973Z"
    },
    "papermill": {
     "duration": 0.016623,
     "end_time": "2024-11-01T17:21:19.290600",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.273977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def init_dataloader(df = None, data_dir=\"/kaggle/input/preprocessed-brats23/Images\", batch_size=64, mode=\"gan\", transform=None, iterator=False):\n",
    "    tf = time.time()\n",
    "    if df is None : \n",
    "        df = pd.read_csv(\"/kaggle/input/preprocessed-brats23/labels.csv\")\n",
    "        df,_ = train_test_split(df, test_size=0.4, stratify=df['label'], random_state=42)\n",
    "    # Define shuffle based on mode (assuming \"attack\" mode does not shuffle data)\n",
    "    shuffle_flag = False if mode == \"attack\" else True\n",
    "\n",
    "    # Initialize the dataset with the MRIDataset class\n",
    "    # Define image transformations (normalization can be adjusted based on data needs)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((240, 240)),  # Ensure image size is 240x240\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = MRIDataset(df=df, data_dir=data_dir, transform=transform)\n",
    "\n",
    "    # Create the DataLoader\n",
    "    if iterator:\n",
    "        data_loader = DataLoader(dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=shuffle_flag,\n",
    "                                 drop_last=True,\n",
    "                                 num_workers=0,\n",
    "                                 pin_memory=True).__iter__()\n",
    "    else:\n",
    "        data_loader = DataLoader(dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=shuffle_flag,\n",
    "                                 drop_last=True,\n",
    "                                 num_workers=2,\n",
    "                                 pin_memory=True)\n",
    "\n",
    "    interval = time.time() - tf\n",
    "    print(f'Initializing data loader took {interval:.2f} seconds')\n",
    "    \n",
    "    return dataset, data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c0a6195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.303397Z",
     "iopub.status.busy": "2024-11-01T17:21:19.303130Z",
     "iopub.status.idle": "2024-11-01T17:21:19.333562Z",
     "shell.execute_reply": "2024-11-01T17:21:19.332761Z"
    },
    "papermill": {
     "duration": 0.03914,
     "end_time": "2024-11-01T17:21:19.335463",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.296323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.utils as tvls\n",
    "def save_tensor_images(images, filename, nrow = None, normalize = True):\n",
    "    if not nrow:\n",
    "        tvls.save_image(images, filename, normalize = normalize, padding=0)\n",
    "    else:\n",
    "        tvls.save_image(images, filename, normalize = normalize, nrow=nrow, padding=0)\n",
    "\n",
    "class HLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "        b = -1.0 * b.sum()\n",
    "        return b\n",
    "\n",
    "# define \"soft\" cross-entropy with pytorch tensor operations\n",
    "def softXEnt (input, target):\n",
    "    targetprobs = nn.functional.softmax (target, dim = 1)\n",
    "    logprobs = nn.functional.log_softmax (input, dim = 1)\n",
    "    return  -(targetprobs * logprobs).sum() / input.shape[0]\n",
    "\n",
    "def log_sum_exp(x, axis = 1):\n",
    "    m = torch.max(x, dim = 1)[0]\n",
    "    return m + torch.log(torch.sum(torch.exp(x - m.unsqueeze(1)), dim = axis))\n",
    "\n",
    "def frequency_penalty_loss(f_imgs):\n",
    "    # Apply 2D Fourier Transform and shift zero-frequency component to center\n",
    "    f_imgs_fft = torch.fft.fft2(f_imgs)\n",
    "    f_imgs_fft_shifted = torch.fft.fftshift(f_imgs_fft)\n",
    "    \n",
    "    # Mask to isolate high-frequency components (outer regions)\n",
    "    h, w = f_imgs_fft_shifted.shape[-2:]\n",
    "    mask = torch.ones_like(f_imgs_fft_shifted, dtype=torch.bool)\n",
    "    mask[:, :, h//4:-h//4, w//4:-w//4] = 0  # Central low-frequency area masked out\n",
    "    \n",
    "    # Calculate the mean magnitude of high-frequency components\n",
    "    high_freq_magnitude = torch.abs(f_imgs_fft_shifted[mask]).mean()\n",
    "    return -high_freq_magnitude  # Negate to reward higher high-frequency content\n",
    "\n",
    "def train_specific_gan():\n",
    "\n",
    "    # Hyperparams\n",
    "    file_path = None\n",
    "    model_name_T = \"VGG16_MRI\"\n",
    "    lr = 0.0002\n",
    "    batch_size = 64\n",
    "    z_dim = 100\n",
    "    epochs = 10\n",
    "    n_critic = 5\n",
    "    dataset_name = \"BraTS23\"\n",
    "    \n",
    "\n",
    "    # Create save folders\n",
    "    root_path = \"/kaggle/working/attack_results\"\n",
    "    save_model_dir = os.path.join(root_path, os.path.join(dataset_name, model_name_T))\n",
    "    save_img_dir = os.path.join(save_model_dir, \"imgs\")\n",
    "    os.makedirs(save_model_dir, exist_ok=True)\n",
    "    os.makedirs(save_img_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Load target model\n",
    "    T = get_augmodel()\n",
    "\n",
    "    # Dataset\n",
    "    data_dir = \"/kaggle/input/preprocessed-brats23/Images\"\n",
    "    dataset, dataloader = init_dataloader(df=None,data_dir=data_dir,batch_size=batch_size)\n",
    "    \n",
    "    # Start Training\n",
    "    print(\"Training GAN for %s\" % model_name_T)\n",
    "\n",
    "#     G = Generator(z_dim)\n",
    "#     DG = MinibatchDiscriminator(n_classes = 2)\n",
    "    \n",
    "#     G = torch.nn.DataParallel(G).cuda()\n",
    "#     DG = torch.nn.DataParallel(DG).cuda()\n",
    "    G,DG = get_GAN(2,100,True)\n",
    "    dg_optimizer = torch.optim.Adam(DG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "    entropy = HLoss()\n",
    "\n",
    "    step = 0\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        _, unlabel_loader1 = init_dataloader(df=None,data_dir = data_dir,batch_size = batch_size, mode=\"gan\",iterator=True)\n",
    "        _,unlabel_loader2 = init_dataloader(df=None,data_dir =data_dir, batch_size =batch_size, mode=\"gan\",iterator=True)\n",
    "        for i, (imgs,label) in enumerate(dataloader):\n",
    "            current_iter = epoch * len(dataloader) + i + 1\n",
    "\n",
    "            step += 1\n",
    "            imgs = imgs.cuda()\n",
    "            bs = imgs.size(0)\n",
    "            x_unlabel_t = next(unlabel_loader1)\n",
    "            x_unlabel2_t = next(unlabel_loader2)\n",
    "            \n",
    "            freeze(G)\n",
    "            unfreeze(DG)\n",
    "\n",
    "            z = torch.randn(bs, z_dim).cuda()\n",
    "            f_imgs = G(z)\n",
    "\n",
    "            y_prob = T(imgs)[-1]\n",
    "            y = torch.argmax(y_prob, dim=1).view(-1)\n",
    "            \n",
    "            x_unlabel = x_unlabel_t[0]\n",
    "            x_unlabel2 = x_unlabel2_t[0]\n",
    "            _, output_label = DG(imgs)\n",
    "            _, output_unlabel = DG(x_unlabel)\n",
    "            _, output_fake =  DG(f_imgs)\n",
    "\n",
    "            loss_lab = softXEnt(output_label, y_prob)\n",
    "            loss_unlab = 0.5*(torch.mean(F.softplus(log_sum_exp(output_unlabel)))-torch.mean(log_sum_exp(output_unlabel))+torch.mean(F.softplus(log_sum_exp(output_fake))))\n",
    "            dg_loss = loss_lab + loss_unlab\n",
    "            \n",
    "            acc = torch.mean((output_label.max(1)[1] == y).float())\n",
    "            \n",
    "            dg_optimizer.zero_grad()\n",
    "            dg_loss.backward()\n",
    "            dg_optimizer.step()\n",
    "\n",
    "            # train G\n",
    "            if step % n_critic == 0:\n",
    "                freeze(DG)\n",
    "                unfreeze(G)\n",
    "                z = torch.randn(bs, z_dim).cuda()\n",
    "                f_imgs = G(z)\n",
    "                mom_gen, output_fake = DG(f_imgs)\n",
    "                mom_unlabel, _ = DG(x_unlabel2)\n",
    "\n",
    "                mom_gen = torch.mean(mom_gen, dim = 0)\n",
    "                mom_unlabel = torch.mean(mom_unlabel, dim = 0)\n",
    "\n",
    "                Hloss = entropy(output_fake)\n",
    "                f_loss = sobel_edge_loss(f_imgs)\n",
    "                g_loss = torch.mean((mom_gen - mom_unlabel).abs()) + 1e-4 * Hloss + 1e-4 *f_loss\n",
    "\n",
    "                g_optimizer.zero_grad()\n",
    "                g_loss.backward()\n",
    "                g_optimizer.step()\n",
    "#                 torch.cuda.empty_cache()\n",
    "\n",
    "        end = time.time()\n",
    "        interval = end - start\n",
    "        \n",
    "        print(\"Epoch:%d \\tTime:%.2f\\tG_loss:%.2f\\t train_acc:%.2f\" % (epoch, interval, g_loss, acc))\n",
    "\n",
    "        torch.save({'state_dict':G.state_dict()}, os.path.join(save_model_dir, \"ep85_improved_loss_{}_G.pt\".format(dataset_name)))\n",
    "        torch.save({'state_dict':DG.state_dict()}, os.path.join(save_model_dir, \"ep85_improved_loss_{}_D.pt\".format(dataset_name)))\n",
    "\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            z = torch.randn(32, z_dim).cuda()\n",
    "            fake_image = G(z)\n",
    "            save_tensor_images(fake_image.detach(), os.path.join(save_img_dir, \"improved_BraTS23_img_{}.png\".format(epoch)), nrow = 8)\n",
    "\n",
    "def sobel_edge_loss(f_imgs):\n",
    "    sobel_x = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=torch.float32, device=f_imgs.device).unsqueeze(0).unsqueeze(0)\n",
    "    sobel_y = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=torch.float32, device=f_imgs.device).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Apply Sobel filter to extract edges in both x and y directions\n",
    "    edges_x = F.conv2d(f_imgs, sobel_x, padding=1)\n",
    "    edges_y = F.conv2d(f_imgs, sobel_y, padding=1)\n",
    "    \n",
    "    # Combine edge intensities\n",
    "    edge_magnitude = torch.sqrt(edges_x * 2 + edges_y * 2)\n",
    "    \n",
    "    # The higher the edge magnitude, the sharper the image details\n",
    "    return -torch.mean(edge_magnitude)  # Negate to encourage sharper details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9ca23e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T17:21:19.348088Z",
     "iopub.status.busy": "2024-11-01T17:21:19.347769Z",
     "iopub.status.idle": "2024-11-01T21:55:08.825197Z",
     "shell.execute_reply": "2024-11-01T21:55:08.824003Z"
    },
    "papermill": {
     "duration": 16429.486761,
     "end_time": "2024-11-01T21:55:08.828016",
     "exception": false,
     "start_time": "2024-11-01T17:21:19.341255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
      "100%|██████████| 528M/528M [00:02<00:00, 225MB/s]\n",
      "/tmp/ipykernel_23/745348162.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data loader took 0.15 seconds\n",
      "Training GAN for VGG16_MRI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2304733014.py:10: FutureWarning: `nn.init.normal` is now deprecated in favor of `nn.init.normal_`.\n",
      "  init.normal(self.T, 0, 1)\n",
      "/tmp/ipykernel_23/2646580041.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp_G = torch.load(path_G)\n",
      "/tmp/ipykernel_23/2646580041.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp_D = torch.load(path_D)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Pretrained Model (Specific GAN)\n",
      "Initializing data loader took 0.10 seconds\n",
      "Initializing data loader took 0.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:117: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return F.linear(input, self.weight, self.bias)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 \tTime:1836.44\tG_loss:nan\t train_acc:0.73\n",
      "Initializing data loader took 0.09 seconds\n",
      "Initializing data loader took 0.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 \tTime:1621.85\tG_loss:nan\t train_acc:0.50\n",
      "Initializing data loader took 0.10 seconds\n",
      "Initializing data loader took 0.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2 \tTime:1630.79\tG_loss:nan\t train_acc:0.75\n",
      "Initializing data loader took 0.09 seconds\n",
      "Initializing data loader took 0.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3 \tTime:1608.68\tG_loss:nan\t train_acc:0.67\n",
      "Initializing data loader took 0.10 seconds\n",
      "Initializing data loader took 0.10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4 \tTime:1622.05\tG_loss:nan\t train_acc:0.58\n",
      "Initializing data loader took 0.09 seconds\n",
      "Initializing data loader took 0.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5 \tTime:1633.28\tG_loss:nan\t train_acc:0.73\n",
      "Initializing data loader took 0.10 seconds\n",
      "Initializing data loader took 0.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6 \tTime:1625.04\tG_loss:nan\t train_acc:0.59\n",
      "Initializing data loader took 0.10 seconds\n",
      "Initializing data loader took 0.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7 \tTime:1608.31\tG_loss:nan\t train_acc:0.62\n",
      "Initializing data loader took 0.10 seconds\n",
      "Initializing data loader took 0.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8 \tTime:1604.99\tG_loss:nan\t train_acc:0.70\n",
      "Initializing data loader took 0.11 seconds\n",
      "Initializing data loader took 0.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9 \tTime:1591.89\tG_loss:nan\t train_acc:0.64\n"
     ]
    }
   ],
   "source": [
    "train_specific_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "698fda8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T21:55:08.855179Z",
     "iopub.status.busy": "2024-11-01T21:55:08.854793Z",
     "iopub.status.idle": "2024-11-01T21:55:08.862477Z",
     "shell.execute_reply": "2024-11-01T21:55:08.861617Z"
    },
    "papermill": {
     "duration": 0.022751,
     "end_time": "2024-11-01T21:55:08.864503",
     "exception": false,
     "start_time": "2024-11-01T21:55:08.841752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_GAN2(n_classes,z_dims):\n",
    "    G = Generator(z_dims)\n",
    "    D = MinibatchDiscriminator(n_classes=n_classes)\n",
    "    \n",
    "    G = torch.nn.DataParallel(G).to(device)\n",
    "    D = torch.nn.DataParallel(D).to(device)\n",
    "#     root_path = \"/kaggle/working/attack_results\"\n",
    "#     save_model_dir = os.path.join(root_path, os.path.join(\"BraTS23\", \"VGG16_MRI\"))\n",
    "    path = \"/kaggle/input/brats23-gan-epoch50/pytorch/default/1\"\n",
    "    path_G = os.path.join(path, \"new_improved_{}_G.pt\".format(\"BraTS23\"))\n",
    "    path_D = os.path.join(path, \"new_improved_{}_D.pt\".format(\"BraTS23\"))\n",
    "    ckp_G = torch.load(path_G)\n",
    "    G.load_state_dict(ckp_G['state_dict'], strict=True)\n",
    "    ckp_D = torch.load(path_D)\n",
    "    D.load_state_dict(ckp_D['state_dict'], strict=True)\n",
    "    return G,D\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc3f3776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T21:55:08.892231Z",
     "iopub.status.busy": "2024-11-01T21:55:08.891925Z",
     "iopub.status.idle": "2024-11-01T21:55:08.898034Z",
     "shell.execute_reply": "2024-11-01T21:55:08.897179Z"
    },
    "papermill": {
     "duration": 0.022412,
     "end_time": "2024-11-01T21:55:08.900181",
     "exception": false,
     "start_time": "2024-11-01T21:55:08.877769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the modified Generator class is already defined as `Generator240x240`\n",
    "def test_gan():\n",
    "#         generator = GeneratorMRI(in_dim=100, dim=64)\n",
    "        generator,_ = get_GAN2(2,100)\n",
    "        generator.eval()\n",
    "        noise = torch.randn(1, 100)\n",
    "        with torch.no_grad():\n",
    "            generated_image = generator(noise)\n",
    "        generated_image = generated_image.squeeze(0).cpu().numpy()\n",
    "        print(generated_image.shape)\n",
    "        # Convert the generated image to a 2D array\n",
    "        generated_image = np.squeeze(generated_image)  # Remove the channel dimension for grayscale\n",
    "\n",
    "        # Plot the generated image\n",
    "        plt.imshow(generated_image, cmap='gray')\n",
    "        plt.axis('off')  # Turn off axis labels\n",
    "        plt.show()\n",
    "# test_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371f693a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T21:55:08.923162Z",
     "iopub.status.busy": "2024-11-01T21:55:08.922833Z",
     "iopub.status.idle": "2024-11-01T21:55:08.927994Z",
     "shell.execute_reply": "2024-11-01T21:55:08.927260Z"
    },
    "papermill": {
     "duration": 0.018837,
     "end_time": "2024-11-01T21:55:08.929909",
     "exception": false,
     "start_time": "2024-11-01T21:55:08.911072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# G,D = get_GAN2(2,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68cc4ae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T21:55:08.953063Z",
     "iopub.status.busy": "2024-11-01T21:55:08.952772Z",
     "iopub.status.idle": "2024-11-01T21:55:08.958378Z",
     "shell.execute_reply": "2024-11-01T21:55:08.957546Z"
    },
    "papermill": {
     "duration": 0.019191,
     "end_time": "2024-11-01T21:55:08.960198",
     "exception": false,
     "start_time": "2024-11-01T21:55:08.941007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_models(G):\n",
    "        generator = G\n",
    "        generator.eval()\n",
    "        noise = torch.randn(1, 100)\n",
    "        with torch.no_grad():\n",
    "            generated_image = generator(noise)\n",
    "        generated_image = generated_image.squeeze(0).cpu().numpy()\n",
    "#         print(generated_image.shape)\n",
    "        # Convert the generated image to a 2D array\n",
    "        generated_image = np.squeeze(generated_image)  # Remove the channel dimension for grayscale\n",
    "\n",
    "        # Plot the generated image\n",
    "        plt.imshow(generated_image, cmap='gray')\n",
    "        plt.axis('off')  # Turn off axis labels\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b196d42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T21:55:08.982849Z",
     "iopub.status.busy": "2024-11-01T21:55:08.982561Z",
     "iopub.status.idle": "2024-11-01T21:55:08.986029Z",
     "shell.execute_reply": "2024-11-01T21:55:08.985191Z"
    },
    "papermill": {
     "duration": 0.016855,
     "end_time": "2024-11-01T21:55:08.987818",
     "exception": false,
     "start_time": "2024-11-01T21:55:08.970963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     test_models(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d282ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T21:55:09.010831Z",
     "iopub.status.busy": "2024-11-01T21:55:09.010544Z",
     "iopub.status.idle": "2024-11-01T21:55:09.014204Z",
     "shell.execute_reply": "2024-11-01T21:55:09.013358Z"
    },
    "papermill": {
     "duration": 0.017194,
     "end_time": "2024-11-01T21:55:09.016010",
     "exception": false,
     "start_time": "2024-11-01T21:55:08.998816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from IPython.display import display\n",
    "\n",
    "# image_path = '/kaggle/input/preprocessed-brats23/Images/BraTS-GLI-00000-000_slice083.png'\n",
    "# img = Image.open(image_path)\n",
    "# display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527dc5e6",
   "metadata": {
    "papermill": {
     "duration": 0.01082,
     "end_time": "2024-11-01T21:55:09.037748",
     "exception": false,
     "start_time": "2024-11-01T21:55:09.026928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5892358,
     "sourceId": 9647841,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 145551,
     "modelInstanceId": 122470,
     "sourceId": 144496,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 148394,
     "modelInstanceId": 125414,
     "sourceId": 147795,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 152752,
     "modelInstanceId": 129892,
     "sourceId": 152947,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16444.076844,
   "end_time": "2024-11-01T21:55:11.942325",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-01T17:21:07.865481",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
